{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-example",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-classic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-adolescent",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Population and samples\n",
    "- Different populations (domains)\n",
    "- Generalization and overfitting\n",
    "- Underfitting and overfitting (bias vs variance)\n",
    "- Regularizations (Lasso, Ridge, Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-logic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Population and sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-basin",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For every machine learning task, we have a target for which should be applied our model:\n",
    "- Images to classify\n",
    "- Security cameras for video analytics\n",
    "- Images to segment (body and foot mesurement)\n",
    "- Cameras for traffic regulation\n",
    "- Text for sentiment analysis\n",
    "- Topic modeling\n",
    "- Images for search\n",
    "- Graphs to classify graphs\n",
    "- Graphs to classify graphs nodes\n",
    "- etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-honduras",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Population does not mean all images for computer vision task\n",
    "<br>\n",
    "\n",
    "All text for NLP tasks\n",
    "<br>\n",
    "\n",
    "All possible graphs for geometric machine learning tasks\n",
    "<br>\n",
    "\n",
    "All posible sounds for sound recognition or speech2text, text2speech, etc tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-moment",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Population (domain) and sample (dataset):\n",
    "<img src=\"images/bias_variance/population_sample_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-primary",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example security camera and video analytics (from personal experience)\n",
    "<img src=\"images/bias_variance/security_camera_1.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-buffalo",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Most tasks are:\n",
    "- Person count (visitors)\n",
    "- Person tracking\n",
    "- Line analysis\n",
    "- Load analysis for different services\n",
    "- Anomaly detection (biheviour)\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-clerk",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example of security camera view:\n",
    "<img src=\"images/bias_variance/security_camera_2.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-yield",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or even more complicated:\n",
    "<img src=\"images/bias_variance/security_camera_3.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-gauge",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For instance this data is not a represintative sample for our population:\n",
    "<img src=\"images/bias_variance/security_camera_4.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-eleven",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Representative sample:\n",
    "- Sample should imitate the population\n",
    "- Because ML model are statistical models and they have to learn distribution\n",
    "    - For instane if we have sample of men we can not estimate average height of grown humen\n",
    "    - Or we have only 15 minutes of video of street, ve can not estimate traffic, and how different is cars on this road\n",
    "        - Cars\n",
    "        - Tracks\n",
    "        - Bus\n",
    "        - Train\n",
    "        - etc\n",
    "    - More complex, we can not detect and trace person with high accuracy for security cameras, which mostly are located higher, if we use images of persons taken by humans in streets\n",
    "- We need text from similar domain in order to estimate sentiments of scientific forum instead of using data from general social networ comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-adoption",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's the example of non representative sample:\n",
    "<img src=\"images/bias_variance/representative_sample_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-passion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Representative sample:\n",
    "<img src=\"images/bias_variance/representative_sample_2.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-immunology",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Representative sample (distribution)\n",
    "<img src=\"images/bias_variance/representative_sample_3.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-paper",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sometimes there are streightforward methods to measure \"representativeness\" level of sample\n",
    "<br>\n",
    "\n",
    "But in most cases it's almost imposible, without human-in-the loop and rough estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-depth",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Back to our security cameras:\n",
    "<br>\n",
    "\n",
    "First we need person detection\n",
    "<br>\n",
    "\n",
    "Datasets and pre-trained which might be found online mostly are collected from car or persons taking the photos or videos, for self-driving cars\n",
    "<br>\n",
    "\n",
    "This data won't be appliable for our population\n",
    "<br>\n",
    "\n",
    "Generalization of models and even humen (which sometimes are overestimated) has it's limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-empty",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Person detection from profile:\n",
    "<img src=\"images/bias_variance/person_detection_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-walter",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Person detection front view\n",
    "<img src=\"images/bias_variance/person_detection_2.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-bouquet",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In many cases model can detect person with different vews but performance is not good enough\n",
    "<br>\n",
    "To solve the problem there might be several ways:\n",
    "- The best way woould be collect appropriate data, lable it and train (or use transfer learning) model\n",
    "- Collect significant amount of data, lable it and mix it with existing data (depends how close is existing data to our population / domain)\n",
    "- Collect significant amount of data, lable it and use it for validation\n",
    "- Find closer, more representative sample to our population\n",
    "- Collect significant amount of data, lable it, find closer, more representative sample to our population, mix them and use it for validation\n",
    "- Collect significant amount of data, lable it, find closer, more representative sample to our population, mix them and train (or use transfer learning) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-spain",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Person detection more close to our population:\n",
    "<img src=\"images/bias_variance/person_detection_3.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-prefix",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Person detection, better fit for our population:\n",
    "<img src=\"images/bias_variance/person_detection_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-button",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting (bias) and underfitting (variance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "viral-river",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Under fitting when model has low accuracy and overfitting when model has high accuracy on sample (training set) but can not generalize on population:\n",
    "<br>\n",
    "<img src=\"images/bias_variance/underfitting_and_overfitting_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-halifax",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example for classification:\n",
    "<img src=\"images/bias_variance/underfitting_and_overfitting_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-intensity",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More precise view of outliers:\n",
    "<img src=\"images/bias_variance/underfitting_and_overfitting_3.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-pledge",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Examples here are shown for sample only (interpolation):\n",
    "<br>\n",
    "<img src=\"images/bias_variance/underfitting_and_overfitting_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-chapel",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reason might be non representative sample:\n",
    "<br>\n",
    "<img src=\"images/bias_variance/underfitting_and_overfitting_5.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-scout",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or it might be rely on particular features:\n",
    "$$\n",
    "f(x) = W \\cdot x + b \\\\\n",
    "f(x) = w_1 \\cdot x_1^2 + w_2 \\cdot x_2^2 + b \\\\\n",
    "f(x) = w_1 \\cdot x_1^2 + w_2 \\cdot x_2^2 + w_3 \\cdot x_3^3 + w_4 \\cdot x_4^4 + b\n",
    "$$\n",
    "<img src=\"images/bias_variance/underfitting_and_overfitting_6.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-mustang",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we reduce the size $w_3$ and $w_4$ and make them almost $0$ then our polinomial model will approximately become a quadratic model and will fit our data\n",
    "<br>\n",
    "\n",
    "There are many techniuques for feature engineering and feature selection and we will talk about them hopefuly in the future\n",
    "<br>\n",
    "\n",
    "Instead of manually reduce the influence of particular features, let model decide which parameter should be reduced\n",
    "<br>\n",
    "\n",
    "Penalize the cost function: \n",
    "$$\n",
    "C(W, b) = C_0(W, b) + \\lambda \\cdot \\sum_{i=1}^{n}|w_i|\n",
    "$$\n",
    "<br>\n",
    "\n",
    "This will give us constant $\\lambda$ after derivation\n",
    "<br>\n",
    "\n",
    "This method is called $L_1$ (or lasso) regularization and is effective on constant level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-brooklyn",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Penalize the cost function: \n",
    "$$\n",
    "C(W, b) = C_0(W, b) + \\lambda \\cdot \\sum_{i=1}^{n}w_i^2\n",
    "$$\n",
    "<br>\n",
    "\n",
    "This will give us $2 \\cdot \\lambda \\cdot w_i$ after derivation\n",
    "<br>\n",
    "\n",
    "This method is called $L_2$ (or ridge) regularization and is effective on variable level\n",
    "<br>\n",
    "\n",
    "We can change $\\lambda$ with $\\frac{2}{m} \\cdot \\lambda$ and get\n",
    "$$\n",
    "C(W, b) = C_0(W, b) + \\frac{2}{m} \\cdot \\lambda \\cdot \\sum_{i=1}^{n}w_i^2\n",
    "$$\n",
    "\n",
    "This will give us $\\lambda \\cdot w_i$ after derivation\n",
    "<br>\n",
    "\n",
    "All this methods, bounds each $w_i$ in order to make cost lower and distributes them in proper order by the original cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-allergy",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So we can now manipulate $\\lambda$ value and regularize our model:\n",
    "- If lambda is big enough than in order to make loss small weights will become almost $0$ which will give us constant funbctiuon $f(x)=b$ and causes underfitting\n",
    "- If lambda is small enough it won't have an effect on loss and this will causes the overfitting\n",
    "<br>\n",
    "\n",
    "Finding appropriate lambda depends on data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-prairie",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train / Validation / Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-wells",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How can we be sure that training goes correctly, no overfitting and no underfitting?\n",
    "<br>\n",
    "\n",
    "We should have data which is representative and might be used for observation\n",
    "<br>\n",
    "\n",
    "Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-beast",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We split our dataset in training and validation parts\n",
    "- Training is used for model fitting\n",
    "- Validation used for observation, performance measure after some cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-inclusion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training and validation performance curves:\n",
    "<br>\n",
    "<img src=\"images/bias_variance/train_valid_1.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-frequency",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's the example of overfitting:\n",
    "<br>\n",
    "<img src=\"images/bias_variance/train_valid_2.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-constraint",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Early stopping:\n",
    "<br>\n",
    "<img src=\"images/bias_variance/train_valid_3.jpeg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-daughter",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Distance might grow but valudation cost should not go up:\n",
    "<br>\n",
    "<img src=\"images/bias_variance/train_valid_4.png\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-australia",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Also test split is used\n",
    "<br>\n",
    "Validation data is used in training not automaticaly but model is fitted for it by hyperparameters tuning\n",
    "<br>\n",
    "\n",
    "Test data should not be used for training at all (not even on validation level)\n",
    "<br>\n",
    "\n",
    "After training is done, test set should be used for performance estimation et the end\n",
    "<br>\n",
    "\n",
    "Test set should be representative as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-nudist",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Benchmark migt be test set\n",
    "<br>\n",
    "\n",
    "Or might be provided by the client\n",
    "<br>\n",
    "\n",
    "This is the best way to measure performance\n",
    "<br>\n",
    "\n",
    "Because of probabilitic nature of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-direction",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Distribution:\n",
    "- For small datasets: $60$% / $20$% / $20$%\n",
    "- For bigger datasets:  $80$% / $10$% / $10$%\n",
    "- For large datasets:  $95$% / $5$% / $5$%\n",
    "- But it depends on data after all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-nepal",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-lewis",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "<img src=\"images/intro2/questions_2.jpg\" height=\"800\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-aspect",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-croatia",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
