{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965aba33-a7f7-4c4f-ad70-110e218e3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bfeb12-d3af-488e-891b-49c77e38dc7e",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3765d-fe0e-4cb1-983e-43339bb88198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U lightning ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff79e71-b83d-405f-8e7e-5d8eec7a00c8",
   "metadata": {},
   "source": [
    "## Organize Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6fb48-0a1c-447c-907b-719ccd8ffa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8979b8-0cfb-491c-b2f0-87fa47c6962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaff67-a4d8-4be5-a976-3efca5487b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e87f4-e8a6-4f00-99c8-e25c00c5bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e7146-d005-4eda-80be-9e757ddcf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a87569-7cbb-4070-8186-eb9e4c877e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import Accuracy\n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff2759-e577-4017-9450-e837e0ab9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34, resnet\n",
    "from torchvision.datasets import CIFAR10, STL10, wrap_dataset_for_transforms_v2\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd733e83-e4f1-4f32-a1b6-7f28bdb6885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57898efb-bbac-47ab-a9e3-a893444e6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "# from lightning.loggers import CSVLogger\n",
    "# from torch.optim.lr_scheduler import OneCycleLR\n",
    "# from torch.optim.swa_utils import AveragedModel\n",
    "# from torch.utils.data import DataLoader, random_split\n",
    "# from torchmetrics.functional import accuracy\n",
    "# from torchvision.datasets import CIFAR10, STL10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67380f-76b5-4763-9cb9-099d96e47f92",
   "metadata": {},
   "source": [
    "## Initialize Folders for Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1ab04-805c-49d4-851b-ae16cf462b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(dir_path: Path):\n",
    "    dir_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035353e-5682-42fb-95b5-4e52ff8bac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('data')\n",
    "MODELS = Path('models')\n",
    "finetune = MODELS / 'resnet_cifar'\n",
    "simclr = MODELS / 'simclr'\n",
    "CHECKPOINT_PATH = simclr / 'checkpoints'\n",
    "CIFAR10_PATH = DATA / 'cifar10'\n",
    "STL10_PATH = DATA / 'stl10'\n",
    "makedirs(finetune)\n",
    "makedirs(CIFAR10_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0bae89-1f6b-44e5-bfd6-ab618779c888",
   "metadata": {},
   "source": [
    "## Initialize Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511aa17-7dfb-407e-86b7-bacdb83f7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_device():\n",
    "    # For the most part I'll try to import functions and classes near\n",
    "    # where they are used\n",
    "    # to make it clear where they come from.\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6644c11-583c-4965-89ae-eab3bb17150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = init_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44051b9f-f7b7-4ef6-85e8-5b33a45b78b0",
   "metadata": {},
   "source": [
    "## Initialize Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653eb25b-6061-4b4b-b62b-ef0b80395f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c823f4-1921-4d43-8229-4878de3808ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = CIFAR10_PATH\n",
    "BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cfceec-8a19-4434-bb70-3ed14415ed3f",
   "metadata": {},
   "source": [
    "## Play with Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8c7b-b05a-4a1c-a32b-30f1873187a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import astronaut\n",
    "from torchvision.io import decode_image, encode_jpeg, encode_png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd33cf0-edc1-4054-8dd9-506191f312c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = astronaut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03cfaab-523d-4349-9f41-2998cb1f30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "astr_path = Path('images') / 'augments' / 'astronauts.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07420917-0bbf-47a0-a733-795a91a13dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = decode_image(astr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ebf25-1c49-4737-beae-b739147199ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a0d9b-c1c3-4887-8d13-a29eea8a8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pair[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc94e63-040d-457f-839b-954da7bf7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imt = v2.ToTensor()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8dc09-e227-4371-a38e-e4e66e56962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    # v2.RandomResizedCrop(size=(30, 30)),\n",
    "    v2.RandomHorizontalFlip(p=1),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    # v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d81a7-368c-46cc-9643-1268a5125ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transforms(pair)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7b49b-9c8c-4f51-bd35-4dda075923f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095976f6-7ff2-4a79-b0b9-2602c56c82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imt = torch.unsqueeze(v2.ToTensor()(img), 0)\n",
    "imt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1748d83-f23e-4763-9029-ce0dd15940dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = v2.ColorJitter()(imt)\n",
    "plt.imshow(fmg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0802e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section A: Transfer Learning with Pretrained ResNet34 Backbone\n",
    "\n",
    "In this section we will fine-tune pretrained ResNet34 modelon using PyTorch Lightning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed025b55-07fe-400d-8016-5f30364f037e",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11db22-094b-46bc-8811-03ccc267e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_normalization = v2.Normalize(\n",
    "    mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "    std=[x / 255.0 for x in [63.0, 62.1, 66.7]],\n",
    ")\n",
    "\n",
    "\n",
    "def split_dataset(dataset, val_split=0.2, train=True):\n",
    "    \"\"\"Splits the dataset into train and validation set.\"\"\"\n",
    "    len_dataset = len(dataset)\n",
    "    splits = get_splits(len_dataset, val_split)\n",
    "    dataset_train, dataset_val = random_split(dataset, splits, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    if train:\n",
    "        return dataset_train\n",
    "    return dataset_val\n",
    "\n",
    "\n",
    "def get_splits(len_dataset, val_split):\n",
    "    \"\"\"Computes split lengths for train and validation set.\"\"\"\n",
    "    if isinstance(val_split, int):\n",
    "        train_len = len_dataset - val_split\n",
    "        splits = [train_len, val_split]\n",
    "    elif isinstance(val_split, float):\n",
    "        val_len = int(val_split * len_dataset)\n",
    "        train_len = len_dataset - val_len\n",
    "        splits = [train_len, val_len]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported type {type(val_split)}\")\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n",
    "train_transforms = v2.Compose(\n",
    "    [\n",
    "        v2.RandomCrop(32, padding=4),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.ToTensor(),\n",
    "        cifar10_normalization,\n",
    "    ]\n",
    ")\n",
    "test_transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToTensor(),\n",
    "        cifar10_normalization,\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_train = CIFAR10(CIFAR10_PATH, train=True, download=True, transform=train_transforms)\n",
    "dataset_val = CIFAR10(CIFAR10_PATH, train=True, download=True, transform=test_transforms)\n",
    "dataset_train = split_dataset(dataset_train)\n",
    "dataset_val = split_dataset(dataset_val, train=False)\n",
    "dataset_test = CIFAR10(CIFAR10_PATH, train=False, download=True, transform=test_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a701e8-9b24-403e-98b3-4280438c18df",
   "metadata": {},
   "source": [
    "#### Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72064c-0793-4836-9031-85361a0b7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = resnet34(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a8b51-824d-40c7-9d29-82a3a2fd8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce794029-99f2-48ff-a617-2c7c364b2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = 10\n",
    "in_features = backbone.fc.in_features\n",
    "backbone.fc = nn.Linear(in_features, target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc048213-62c1-4899-b297-db634e521bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f271f5-7368-49f2-9d4d-14ccfc1e0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # init a pretrained resnet\n",
    "        backbone = resnet34(weights=\"DEFAULT\")\n",
    "        \n",
    "        # use the pretrained model to classify cifar-10 (10 image classes)\n",
    "        target_features = 10\n",
    "        in_features = backbone.fc.in_features\n",
    "        backbone.fc = nn.Linear(in_features, target_features)\n",
    "        self.model = backbone\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=10)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, stage=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, stage=\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=0.05,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        steps_per_epoch = 45000 // BATCH_SIZE\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\": OneCycleLR(\n",
    "                optimizer,\n",
    "                0.1,\n",
    "                epochs=self.trainer.max_epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6aa05-50f9-410c-91ef-3f5b3e29b18f",
   "metadata": {},
   "source": [
    "#### Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a5543-2af4-437d-b721-fcf2eb33a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    "    callbacks=[LearningRateMonitor(logging_interval=\"step\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830788c4-9e8f-40cd-993c-e1415a1c7b96",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd231c5-52c0-42c0-bafe-27a7897ccc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabda311-da87-42ff-baca-47f9d61b4dc1",
   "metadata": {},
   "source": [
    "## Train SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1878d-409d-42c7-935e-7c5f12e341fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b99592-30c9-4bb5-82be-36255aff9df1",
   "metadata": {},
   "source": [
    "#### Get Pre-trained Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fb72e-d3f8-47f6-be9d-e88a974f6bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial17/\"\n",
    "# Files to download\n",
    "pretrained_files = [\n",
    "    \"SimCLR.ckpt\",\n",
    "    \"ResNet.ckpt\",\n",
    "    \"tensorboards/SimCLR/events.out.tfevents.SimCLR\",\n",
    "    \"tensorboards/classification/ResNet/events.out.tfevents.ResNet\",\n",
    "]\n",
    "pretrained_files += [f\"LogisticRegression_{size}.ckpt\" for size in [10, 20, 50, 100, 200, 500]]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder,\"\n",
    "                \" or contact the author with the full output including the following error:\\n\",\n",
    "                e,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28edbe2e-59d5-40db-aeae-18044ab224a8",
   "metadata": {},
   "source": [
    "### Initialize Contrastive Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4864f-b499-4774-a807-5317cc50b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveTransformations:\n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transforms(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfaccd-d99e-461a-ba68-b3b3a2917489",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_transforms = v2.Compose(\n",
    "    [\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomResizedCrop(size=96),\n",
    "        v2.RandomApply([v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "        v2.RandomGrayscale(p=0.2),\n",
    "        v2.GaussianBlur(kernel_size=9),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affe325-e3e9-4df2-abb8-9b254b0aa138",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eebc1c-5d11-4a5f-ac43-c9534a5357a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = STL10(\n",
    "    root=STL10_PATH,\n",
    "    split=\"unlabeled\",\n",
    "    download=True,\n",
    "    transform=ContrastiveTransformations(contrast_transforms, n_views=2),\n",
    ")\n",
    "train_data_contrast = STL10(\n",
    "    root=STL10_PATH,\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=ContrastiveTransformations(contrast_transforms, n_views=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab211a3-2826-424b-8835-fafa81ebaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = 6\n",
    "imgs = torch.stack([img for idx in range(NUM_IMAGES) for img in unlabeled_data[idx][0]], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(imgs, nrow=6, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Augmented image examples of the STL10 dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646f6a6-b7e9-46a6-bde5-98fe61ef2d1a",
   "metadata": {},
   "source": [
    "#### Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f4eb6-145b-439e-911f-b3e893fd21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, \"The temperature must be a positive float!\"\n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(\n",
    "            pretrained=False, num_classes=4 * hidden_dim\n",
    "        )  # num_classes is the output size of the last linear layer\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim),\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr / 50\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode=\"train\"):\n",
    "        imgs, _ = batch\n",
    "        imgs = torch.cat(imgs, dim=0)\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = F.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode + \"_loss\", nll)\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat(\n",
    "            [cos_sim[pos_mask][:, None], cos_sim.masked_fill(pos_mask, -9e15)],  # First position positive example\n",
    "            dim=-1,\n",
    "        )\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "        self.log(mode + \"_acc_top1\", (sim_argsort == 0).float().mean())\n",
    "        self.log(mode + \"_acc_top5\", (sim_argsort < 5).float().mean())\n",
    "        self.log(mode + \"_acc_mean_pos\", 1 + sim_argsort.float().mean())\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c64454-4c64-4d96-8d0e-bf21d4959e72",
   "metadata": {},
   "source": [
    "#### Start TensorBoard for Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2115221-55b6-42e5-bd2f-26cabfede6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ../saved_models/tutorial17/tensorboards/SimCLR/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678b77f-9414-44e6-bd71-cbd3fa42db72",
   "metadata": {},
   "source": [
    "#### Setup the Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff7824-e4b6-406a-b31e-9ed7b327ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simclr(batch_size, max_epochs=500, **kwargs):\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, \"SimCLR\"),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc_top5\"),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"SimCLR.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = SimCLR.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        train_loader = data.DataLoader(\n",
    "            unlabeled_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        val_loader = data.DataLoader(\n",
    "            train_data_contrast,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        pl.seed_everything(42)  # To be reproducible\n",
    "        model = SimCLR(max_epochs=max_epochs, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        # Load best checkpoint after training\n",
    "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624c96b-5391-4505-a6e6-b98d269994d4",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1b369-1d75-4c54-b502-cef98d954ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "    def __init__(self, feature_dim, num_classes, lr, weight_decay, max_epochs=100):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Mapping from representation h to classes\n",
    "        self.model = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[int(self.hparams.max_epochs * 0.6), int(self.hparams.max_epochs * 0.8)], gamma=0.1\n",
    "        )\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        feats, labels = batch\n",
    "        preds = self.model(feats)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log(mode + \"_loss\", loss)\n",
    "        self.log(mode + \"_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a1c27-e001-40b9-9b54-8c0da3c0f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_img_data = STL10(root=DATASET_PATH, split=\"train\", download=True, transform=img_transforms)\n",
    "test_img_data = STL10(root=DATASET_PATH, split=\"test\", download=True, transform=img_transforms)\n",
    "\n",
    "print(\"Number of training examples:\", len(train_img_data))\n",
    "print(\"Number of test examples:\", len(test_img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53910416-4dbb-4724-926e-23cd42842237",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataset):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    # Sort images by labels\n",
    "    labels, idxs = labels.sort()\n",
    "    feats = feats[idxs]\n",
    "\n",
    "    return data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c831da-ec1f-4327-b944-dd6670e53797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats_simclr = prepare_data_features(simclr_model, train_img_data)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405410a-4f55-4bb6-8bdf-94599036d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(batch_size, train_feats_data, test_feats_data, model_suffix, max_epochs=100, **kwargs):\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, \"LogisticRegression\"),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=max_epochs,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "        enable_progress_bar=False,\n",
    "        check_val_every_n_epoch=10,\n",
    "    )\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = data.DataLoader(\n",
    "        train_feats_data, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "        test_feats_data, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0\n",
    "    )\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"LogisticRegression_{model_suffix}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = LogisticRegression.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducible\n",
    "        model = LogisticRegression(**kwargs)\n",
    "        trainer.fit(model, train_loader, test_loader)\n",
    "        model = LogisticRegression.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on train and validation set\n",
    "    train_result = trainer.test(model, dataloaders=train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    result = {\"train\": train_result[0][\"test_acc\"], \"test\": test_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7443950-da95-4ccb-a65c-8394377dacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smaller_dataset(original_dataset, num_imgs_per_label):\n",
    "    new_dataset = data.TensorDataset(\n",
    "        *(t.unflatten(0, (10, 500))[:, :num_imgs_per_label].flatten(0, 1) for t in original_dataset.tensors)\n",
    "    )\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d8205-ea26-4e51-b449-7aad2bc57144",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for num_imgs_per_label in [10, 20, 50, 100, 200, 500]:\n",
    "    sub_train_set = get_smaller_dataset(train_feats_simclr, num_imgs_per_label)\n",
    "    _, small_set_results = train_logreg(\n",
    "        batch_size=64,\n",
    "        train_feats_data=sub_train_set,\n",
    "        test_feats_data=test_feats_simclr,\n",
    "        model_suffix=num_imgs_per_label,\n",
    "        feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "        num_classes=10,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-3,\n",
    "    )\n",
    "    results[num_imgs_per_label] = small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1e96a-2ba9-492c-a8f4-9488e0c90e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = sorted(k for k in results)\n",
    "test_scores = [results[k][\"test\"] for k in dataset_sizes]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "plt.plot(\n",
    "    dataset_sizes,\n",
    "    test_scores,\n",
    "    \"--\",\n",
    "    color=\"#000\",\n",
    "    marker=\"*\",\n",
    "    markeredgecolor=\"#000\",\n",
    "    markerfacecolor=\"y\",\n",
    "    markersize=16,\n",
    ")\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(dataset_sizes, labels=dataset_sizes)\n",
    "plt.title(\"STL10 classification over dataset size\", fontsize=14)\n",
    "plt.xlabel(\"Number of images per class\")\n",
    "plt.ylabel(\"Test accuracy\")\n",
    "plt.minorticks_off()\n",
    "plt.show()\n",
    "\n",
    "for k, score in zip(dataset_sizes, test_scores):\n",
    "    print(f\"Test accuracy for {k:3d} images per label: {100*score:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d67f1-6647-442c-bcf8-d33a3686dbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
