{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial I reccomend you create new conda anvironment\n",
    "```bash\n",
    "conda create -n edu python=3.9 jupyter matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda activate edu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install OpenMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```bash \n",
    "! pip install autopep8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "! pip install opencv-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "! pip install -U openmim\n",
    "! mim install mmcv-full\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MMSegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "! git clone https://github.com/open-mmlab/mmsegmentation.git\n",
    "! cd mmsegmentation\n",
    "! pip install -v -e .\n",
    "# \"-v\" means verbose, or more output\n",
    "# \"-e\" means installing a project in editable mode,\n",
    "# thus any local modifications made to the code will take effect without reinstallation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "! pip install mmsegmentation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure workers and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = cpu_count()\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segpath = Path('../mmsegmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "! mim download mmsegmentation --config pspnet_r50-d8_512x1024_40k_cityscapes --dest {segpath}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {segpath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = segpath / 'pspnet_r50-d8_512x1024_40k_cityscapes.py'\n",
    "checkpoint_file = segpath / 'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_segmentor(str(config_file), str(checkpoint_file), device=device)\n",
    "\n",
    "# test a single image and show the results\n",
    "img = str(segpath / 'demo' / 'demo.png') #'test.jpg'  # or img = mmcv.imread(img), which will only load it once\n",
    "result = inference_segmentor(model, img)\n",
    "show_result_pyplot(model, img, result, get_palette('cityscapes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "camvid = path / 'camvid'\n",
    "camvid.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (camvid / 'camvid_tiny.tgz').exists():\n",
    "    ! wget http://files.fast.ai/data/examples/camvid_tiny.tgz -P {camvid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls {camvid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camvid_tiny = camvid / 'camvid_tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not camvid_tiny.exists():\n",
    "    ! tar xf {camvid / 'camvid_tiny.tgz'} -C {camvid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {camvid_tiny}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {camvid_tiny / 'images'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = mmcv.imread(camvid_tiny / 'images/' / '0016E5_07290.png')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_path = camvid_tiny / 'label_colors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not palette_path.exists():\n",
    "    ! wget http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/data/label_colors.txt -P {camvid_tiny}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with palette_path.open('r') as plts:\n",
    "    lines = plts.readlines()\n",
    "    classes = list()\n",
    "    palette = list()\n",
    "    for idx, line in enumerate(lines):\n",
    "        cl_ln = line.strip()\n",
    "        pltte = re.findall('[0-9]+', cl_ln)\n",
    "        cl_nm = re.findall('[A-Z-a-z]+', cl_ln)[0]\n",
    "        palette.append(pltte)\n",
    "        classes.append(cl_nm)\n",
    "        print(idx + 1, pltte, cl_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {camvid_tiny / 'labels'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = camvid_tiny\n",
    "img_dir = 'images'\n",
    "ann_dir = 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/val set randomly\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(data_root / split_dir)\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, img_dir), suffix='.png')]\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "  # select first 4/5 as train set\n",
    "  train_length = int(len(filename_list)*4/5)\n",
    "  f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "  # select last 1/5 as train set\n",
    "  f.writelines(line + '\\n' for line in filename_list[train_length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls {data_root / split_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (data_root / split_dir / 'train.txt').open('r') as spl:\n",
    "    lines = spl.readlines()\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (data_root / split_dir / 'val.txt').open('r') as spl:\n",
    "    lines = spl.readlines()\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module(force=True)\n",
    "class CamvidDataset(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.png', seg_map_suffix='_P.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's take a look at the segmentation map we got\n",
    "# img = Image.open(data_root/ ann_dir / '0016E5_07290_P.png')\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# # create a patch (proxy artist) for every color \n",
    "# patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "#                           label=classes[i]) for i in range(32)]\n",
    "# # put those patched as legend-handles into the legend\n",
    "# plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "#            fontsize='large')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and configure checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = Path('checkpoints')\n",
    "checkpoints.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psp_city_ckp = 'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "psp_city_path = checkpoints / psp_city_ckp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not psp_city_path.exists():\n",
    "    !wget https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth -P checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {checkpoints}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "from mmseg.apis import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_path = segpath / 'configs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {conf_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psp_config = conf_path / 'pspnet'\n",
    "psp_config_city = psp_config / 'pspnet_r50-d8_512x1024_40k_cityscapes.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(str(psp_config_city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {checkpoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 8\n",
    "cfg.model.auxiliary_head.num_classes = 8\n",
    "cfg.model.init_cfg=dict(\n",
    "    type='Pretrained', \n",
    "    checkpoint='open-mmlab://resnet50_v1c'),\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'CamvidDataset'\n",
    "cfg.data_root = str(data_root)\n",
    "\n",
    "cfg.data.samples_per_gpu = 32\n",
    "cfg.data.workers_per_gpu=8\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (256, 256)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(320, 240),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = str(checkpoints / \n",
    "                    'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth')\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "\n",
    "cfg.runner.max_iters = 256\n",
    "cfg.log_config.interval = 32\n",
    "cfg.evaluation.interval = 128\n",
    "cfg.checkpoint_config.interval = 256\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = device\n",
    "cfg.cudnn_benchmark = True\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del cfg.model.backbone.pretrained\n",
    "except:\n",
    "    print('cfg.model.backbone.pretrained noes not exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del cfg.model.pretrained\n",
    "except:\n",
    "    print('cfg.model.pretrained noes not exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "! cp {segpath / 'demo' / 'MMSegmentation_Tutorial.ipynb'} 'mmsegmentation_tutorial.ipynb'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the detector\n",
    "model = build_segmentor(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mmcv.imread(str(data_root / img_dir / 'Seq05VD_f01080.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_segmentor(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection with MMDetection library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library MMDetection in part of the OpenMMLab library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pip install -U openmim\n",
    "mim install mmcv-full\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ~/git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "! git clone https://github.com/open-mmlab/mmdetection.git ../mmdetection\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "! cd ../mmdetection; pip install -U -v -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmdet.apis import train_detector, inference_detector, show_result_pyplot, set_random_seed\n",
    "from mmdet.models import build_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure workers and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = cpu_count()\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detpath = Path('../mmdetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_config = detpath / 'configs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcnn_config = det_config / 'faster_rcnn' / 'faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn_checkpoints = Path('checkpoints')\n",
    "fcnn_checkpoints.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {fcnn_checkpoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn_checkpoints_path = fcnn_checkpoints / 'faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fcnn_checkpoints_path.exists():\n",
    "    !wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \\\n",
    "      -O {fcnn_checkpoints_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {det_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {frcnn_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "config = mmcv.Config.fromfile(frcnn_config)\n",
    "# Set pretrained to be None since we do not need pretrained model here\n",
    "config.model.pretrained = None\n",
    "\n",
    "# Initialize the detector\n",
    "model = build_detector(config.model)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = load_checkpoint(model, str(fcnn_checkpoints_path), map_location=device)\n",
    "\n",
    "# Set the classes of models for inference\n",
    "model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "\n",
    "# We need to set the model's cfg for inference\n",
    "model.cfg = config\n",
    "\n",
    "# Convert the model to GPU\n",
    "model.to(device)\n",
    "# Convert the model into evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the detector to do inference\n",
    "img = detpath / 'demo' / 'demo.jpg'\n",
    "result = inference_detector(model, str(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the result\n",
    "show_result_pyplot(model, img, result, score_thr=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.home() /'.kaggle'\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = Path('data') / 'wheat'\n",
    "datasets.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls {datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheet_path = datasets / 'global-wheat-detection.zip'\n",
    "wheet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_not_exists = not wheet_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = path / 'kaggle.json'\n",
    "if zip_not_exists:\n",
    "    api_token = {\"username\":\"yout-user\",\"key\":\"your-key\"}\n",
    "    with json_path.open(mode='w') as file:\n",
    "        json.dump(api_token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if zip_not_exists:\n",
    "    ! chmod 600 ~/.kaggle/kaggle.json\n",
    "    ! kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zip_not_exists:\n",
    "    ! kaggle competitions download -c global-wheat-detection -p {datasets}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "datasets = Path('/content') / 'drive' / 'My\\ Drive' / 'datasets'\n",
    "! ls {datasets}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {data_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_not_exists = not (data_path / 'sample_submission.csv').exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if csv_file_not_exists:\n",
    "    zip_ref = zipfile.ZipFile(data_path / 'global-wheat-detection.zip', 'r')\n",
    "    zip_ref.extractall(path=data_path)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = data_path / 'train' \n",
    "csv_path = data_path / 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = df.source.unique().tolist()\n",
    "classes = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "LABEL_NAMES = classes\n",
    "LABEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.image_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    data_infos = []\n",
    "    image_df = df.image_id.unique()\n",
    "    items = len(image_df)\n",
    "    image_df = enumerate(image_df)\n",
    "    with tqdm(image_df, total=items, desc='converting data') as prog:\n",
    "        for image_id, img_name in prog:\n",
    "            record = dict()\n",
    "            image_df = df[df.image_id == img_name]\n",
    "            record['filename'] = f'{img_name}.jpg'\n",
    "            record['image_id'] = image_id\n",
    "            record['height'] = int(image_df.iloc[0].height)\n",
    "            record['width'] = int(image_df.iloc[0].width)\n",
    "            bboxes = list()\n",
    "            labels = list()\n",
    "            for _, row in image_df.iterrows():\n",
    "                bbox_raw = json.loads(row.bbox)\n",
    "                bbox = [int(bbox_raw[0]), int(bbox_raw[1]),\n",
    "                        int(bbox_raw[0] + bbox_raw[2]), int(bbox_raw[1] + bbox_raw[3])]\n",
    "                bboxes.append(bbox)\n",
    "                category_id=classes.get(row.source, 0)\n",
    "                labels.append(category_id)\n",
    "            record['ann'] = dict(\n",
    "                bboxes=np.array(bboxes).astype(np.float32),\n",
    "                labels=np.array(labels).astype(np.int64))\n",
    "            data_infos.append(record)\n",
    "\n",
    "    return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pickle = data_path / 'dataset.pkl'\n",
    "train_pickle = data_path / 'train.pkl'\n",
    "val_pickle = data_path / 'val.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_not_exists = not data_pickle.exists()\n",
    "train__not_exists = not train_pickle.exists()\n",
    "val_not_exists = not val_pickle.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_not_exists:\n",
    "    data_dicts = create_dataset(df)\n",
    "elif train__not_exists or val_not_exists:\n",
    "    with data_pickle.open(mode='rb') as fp:\n",
    "        data_dicts = pickle.load(fp)\n",
    "else:\n",
    "    print(f'All filrs: {data_pickle} {train_pickle} {val_pickle} already there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train__not_exists or val_not_exists:\n",
    "    data_dicts[-1]['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train__not_exists or val_not_exists:\n",
    "    total_data = len(data_dicts)\n",
    "    split_data = total_data - (total_data// 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train__not_exists or val_not_exists:\n",
    "    train_dicts = data_dicts[:split_data]\n",
    "    val_dicts = data_dicts[split_data:]\n",
    "    len(train_dicts), len(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_not_exists:\n",
    "    with data_pickle.open(mode='wb') as fp:\n",
    "        pickle.dump(data_dicts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train__not_exists:\n",
    "    with train_pickle.open(mode='wb') as fp:\n",
    "        pickle.dump(train_dicts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_not_exists:\n",
    "    with val_pickle.open(mode='wb') as fp:\n",
    "        pickle.dump(val_dicts, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with data_pickle.open(mode='rb') as fp:\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with train_pickle.open(mode='rb') as fp:\n",
    "    train_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with val_pickle.open(mode='rb') as fp:\n",
    "    val_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module(force=True)\n",
    "class WheatDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = list(LABEL_NAMES.keys())\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        with Path(ann_file).open(mode='rb') as fp:\n",
    "            data_infos = pickle.load(fp)\n",
    "        \n",
    "        return data_infos\n",
    "\n",
    "    def get_ann_info(self, idx):\n",
    "        return self.data_infos[idx]['ann']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(str(frcnn_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = str(data_path)\n",
    "data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'WheatDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.test.type = 'WheatDataset'\n",
    "cfg.data.test.data_root = data_root\n",
    "cfg.data.test.ann_file = 'val.pkl'\n",
    "cfg.data.test.img_prefix = 'train'\n",
    "\n",
    "cfg.data.train.type = 'WheatDataset'\n",
    "cfg.data.train.data_root = data_root\n",
    "cfg.data.train.ann_file = 'train.pkl'\n",
    "cfg.data.train.img_prefix = 'train'\n",
    "\n",
    "cfg.data.val.type = 'WheatDataset'\n",
    "cfg.data.val.data_root = data_root\n",
    "cfg.data.val.ann_file = 'val.pkl'\n",
    "cfg.data.val.img_prefix = 'train'\n",
    "\n",
    "cfg.data.samples_per_gpu=bs // 4\n",
    "cfg.data.workers_per_gpu=workers\n",
    "\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.roi_head.bbox_head.num_classes = len(LABEL_NAMES)\n",
    "# If we need to finetune a model based on a pre-trained detector, we need to\n",
    "# use load_from to set the path of checkpoints.\n",
    "cfg.load_from = str(fcnn_checkpoints_path)\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 32\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 6\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.cudnn_benchmark = True\n",
    "cfg.device = device\n",
    "\n",
    "# We can also use tensorboard to log the training process\n",
    "cfg.log_config.hooks = [\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='TensorboardLoggerHook')]\n",
    "\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the detector\n",
    "model = build_detector(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 14:54:59,497 - mmdet - INFO - Epoch [10][160/317]\tlr: 2.500e-04, eta: 0:06:39, time: 0.540, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0378, loss_rpn_bbox: 0.1197, loss_cls: 0.2700, acc: 88.0592, loss_bbox: 0.4652, loss: 0.8927\n",
      "2022-06-22 14:55:17,098 - mmdet - INFO - Epoch [10][192/317]\tlr: 2.500e-04, eta: 0:06:23, time: 0.549, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0422, loss_rpn_bbox: 0.1199, loss_cls: 0.2765, acc: 87.8784, loss_bbox: 0.4710, loss: 0.9097\n",
      "2022-06-22 14:55:34,654 - mmdet - INFO - Epoch [10][224/317]\tlr: 2.500e-04, eta: 0:06:07, time: 0.549, data_time: 0.027, memory: 8226, loss_rpn_cls: 0.0404, loss_rpn_bbox: 0.1192, loss_cls: 0.2743, acc: 87.8891, loss_bbox: 0.4681, loss: 0.9020\n",
      "2022-06-22 14:55:52,031 - mmdet - INFO - Epoch [10][256/317]\tlr: 2.500e-04, eta: 0:05:51, time: 0.543, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0410, loss_rpn_bbox: 0.1182, loss_cls: 0.2744, acc: 88.0348, loss_bbox: 0.4608, loss: 0.8944\n",
      "2022-06-22 14:56:09,198 - mmdet - INFO - Epoch [10][288/317]\tlr: 2.500e-04, eta: 0:05:35, time: 0.536, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0405, loss_rpn_bbox: 0.1197, loss_cls: 0.2750, acc: 87.9227, loss_bbox: 0.4659, loss: 0.9011\n",
      "2022-06-22 14:56:45,473 - mmdet - INFO - Epoch [11][32/317]\tlr: 2.500e-04, eta: 0:05:02, time: 0.631, data_time: 0.108, memory: 8226, loss_rpn_cls: 0.0415, loss_rpn_bbox: 0.1200, loss_cls: 0.2723, acc: 88.0081, loss_bbox: 0.4620, loss: 0.8958\n",
      "2022-06-22 14:57:02,742 - mmdet - INFO - Epoch [11][64/317]\tlr: 2.500e-04, eta: 0:04:46, time: 0.540, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0404, loss_rpn_bbox: 0.1218, loss_cls: 0.2685, acc: 88.1851, loss_bbox: 0.4626, loss: 0.8934\n",
      "2022-06-22 14:57:20,161 - mmdet - INFO - Epoch [11][96/317]\tlr: 2.500e-04, eta: 0:04:31, time: 0.545, data_time: 0.027, memory: 8226, loss_rpn_cls: 0.0388, loss_rpn_bbox: 0.1199, loss_cls: 0.2770, acc: 87.7945, loss_bbox: 0.4769, loss: 0.9127\n",
      "2022-06-22 14:57:37,997 - mmdet - INFO - Epoch [11][128/317]\tlr: 2.500e-04, eta: 0:04:15, time: 0.556, data_time: 0.024, memory: 8226, loss_rpn_cls: 0.0392, loss_rpn_bbox: 0.1202, loss_cls: 0.2695, acc: 88.1767, loss_bbox: 0.4625, loss: 0.8914\n",
      "2022-06-22 14:57:55,355 - mmdet - INFO - Epoch [11][160/317]\tlr: 2.500e-04, eta: 0:03:59, time: 0.543, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0380, loss_rpn_bbox: 0.1190, loss_cls: 0.2724, acc: 87.9555, loss_bbox: 0.4630, loss: 0.8924\n",
      "2022-06-22 14:58:12,615 - mmdet - INFO - Epoch [11][192/317]\tlr: 2.500e-04, eta: 0:03:43, time: 0.539, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0402, loss_rpn_bbox: 0.1192, loss_cls: 0.2798, acc: 87.7378, loss_bbox: 0.4795, loss: 0.9187\n",
      "2022-06-22 14:58:29,873 - mmdet - INFO - Epoch [11][224/317]\tlr: 2.500e-04, eta: 0:03:27, time: 0.540, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0382, loss_rpn_bbox: 0.1177, loss_cls: 0.2705, acc: 88.1706, loss_bbox: 0.4629, loss: 0.8894\n",
      "2022-06-22 14:58:47,192 - mmdet - INFO - Epoch [11][256/317]\tlr: 2.500e-04, eta: 0:03:11, time: 0.541, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.1215, loss_cls: 0.2754, acc: 87.8670, loss_bbox: 0.4757, loss: 0.9146\n",
      "2022-06-22 14:59:04,739 - mmdet - INFO - Epoch [11][288/317]\tlr: 2.500e-04, eta: 0:02:55, time: 0.548, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0366, loss_rpn_bbox: 0.1171, loss_cls: 0.2703, acc: 88.0989, loss_bbox: 0.4583, loss: 0.8823\n",
      "2022-06-22 14:59:40,934 - mmdet - INFO - Epoch [12][32/317]\tlr: 2.500e-05, eta: 0:02:23, time: 0.631, data_time: 0.107, memory: 8226, loss_rpn_cls: 0.0409, loss_rpn_bbox: 0.1194, loss_cls: 0.2728, acc: 87.9524, loss_bbox: 0.4734, loss: 0.9065\n",
      "2022-06-22 14:59:57,970 - mmdet - INFO - Epoch [12][64/317]\tlr: 2.500e-05, eta: 0:02:07, time: 0.533, data_time: 0.027, memory: 8226, loss_rpn_cls: 0.0400, loss_rpn_bbox: 0.1191, loss_cls: 0.2832, acc: 87.5526, loss_bbox: 0.4787, loss: 0.9210\n",
      "2022-06-22 15:00:15,631 - mmdet - INFO - Epoch [12][96/317]\tlr: 2.500e-05, eta: 0:01:51, time: 0.553, data_time: 0.026, memory: 8226, loss_rpn_cls: 0.0397, loss_rpn_bbox: 0.1166, loss_cls: 0.2735, acc: 87.9044, loss_bbox: 0.4624, loss: 0.8922\n",
      "2022-06-22 15:00:33,296 - mmdet - INFO - Epoch [12][128/317]\tlr: 2.500e-05, eta: 0:01:35, time: 0.551, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0390, loss_rpn_bbox: 0.1228, loss_cls: 0.2733, acc: 87.9654, loss_bbox: 0.4638, loss: 0.8990\n",
      "2022-06-22 15:00:50,605 - mmdet - INFO - Epoch [12][160/317]\tlr: 2.500e-05, eta: 0:01:19, time: 0.542, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0426, loss_rpn_bbox: 0.1206, loss_cls: 0.2720, acc: 87.9936, loss_bbox: 0.4649, loss: 0.9002\n",
      "2022-06-22 15:01:08,424 - mmdet - INFO - Epoch [12][192/317]\tlr: 2.500e-05, eta: 0:01:03, time: 0.556, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0370, loss_rpn_bbox: 0.1159, loss_cls: 0.2718, acc: 88.0165, loss_bbox: 0.4605, loss: 0.8852\n",
      "2022-06-22 15:01:25,690 - mmdet - INFO - Epoch [12][224/317]\tlr: 2.500e-05, eta: 0:00:46, time: 0.540, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0406, loss_rpn_bbox: 0.1198, loss_cls: 0.2717, acc: 88.0554, loss_bbox: 0.4660, loss: 0.8981\n",
      "2022-06-22 15:01:43,052 - mmdet - INFO - Epoch [12][256/317]\tlr: 2.500e-05, eta: 0:00:30, time: 0.542, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0405, loss_rpn_bbox: 0.1197, loss_cls: 0.2727, acc: 87.9974, loss_bbox: 0.4678, loss: 0.9006\n",
      "2022-06-22 15:02:00,292 - mmdet - INFO - Epoch [12][288/317]\tlr: 2.500e-05, eta: 0:00:14, time: 0.538, data_time: 0.025, memory: 8226, loss_rpn_cls: 0.0376, loss_rpn_bbox: 0.1151, loss_cls: 0.2653, acc: 88.4239, loss_bbox: 0.4568, loss: 0.8747\n",
      "2022-06-22 15:02:15,969 - mmdet - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 843/843, 26.3 task/s, elapsed: 32s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 15:02:50,172 - mmdet - INFO - \n",
      "+-----------+-------+-------+--------+-------+\n",
      "| class     | gts   | dets  | recall | ap    |\n",
      "+-----------+-------+-------+--------+-------+\n",
      "| usask_1   | 0     | 10133 | 0.000  | 0.000 |\n",
      "| arvalis_1 | 0     | 536   | 0.000  | 0.000 |\n",
      "| inrae_1   | 0     | 2199  | 0.000  | 0.000 |\n",
      "| ethz_1    | 0     | 210   | 0.000  | 0.000 |\n",
      "| arvalis_3 | 5538  | 32245 | 0.925  | 0.456 |\n",
      "| rres_1    | 20236 | 0     | 0.000  | 0.000 |\n",
      "| arvalis_2 | 4179  | 0     | 0.000  | 0.000 |\n",
      "+-----------+-------+-------+--------+-------+\n",
      "| mAP       |       |       |        | 0.152 |\n",
      "+-----------+-------+-------+--------+-------+\n",
      "2022-06-22 15:02:50,219 - mmdet - INFO - Epoch(val) [12][843]\tAP50: 0.1520, mAP: 0.1521\n"
     ]
    }
   ],
   "source": [
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look into the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load tensorboard in colab\n",
    "%load_ext tensorboard\n",
    "\n",
    "# see curves in tensorboard\n",
    "%tensorboard --logdir ./tutorial_exps --port 8899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = data_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mmcv.imread(str(test_path /'2fd875eaa.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_detector(model, img)\n",
    "show_result_pyplot(model, img, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
