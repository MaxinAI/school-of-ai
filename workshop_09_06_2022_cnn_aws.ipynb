{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL.Image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import (transforms, datasets)\n",
    "from torchvision import models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "! conda install pytorch torchvision torchaudio -c pytorch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "! pip install pytorch-lightning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MNIST classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "lr = 0.1\n",
    "bs = 2 * 64\n",
    "gamma = 0.7\n",
    "save_model = False\n",
    "log_interval = 10\n",
    "dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298131\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.825917\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.210144\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.943850\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.885442\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.628774\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.852532\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.514832\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.663228\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.546291\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.369553\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.382517\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.345922\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.581012\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.551198\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.285307\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.587430\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.492382\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.152887\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.157820\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.605864\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.214538\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.408203\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.431890\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.302423\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.262685\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.289928\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.346182\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.285184\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.238608\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.171082\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.206636\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.389096\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.246713\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.181946\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.247291\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.269295\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.196403\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.160471\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.208033\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.262221\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.084248\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.155387\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.111609\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.259864\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.134418\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.212443\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.253332\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.099127\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.160872\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.248201\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.078073\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.382082\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.265358\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.180833\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.159925\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.174046\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.174370\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.268109\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.045430\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.064726\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.303921\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.148722\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.217012\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.105854\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.286324\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.357011\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.104774\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.115187\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.231132\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.183856\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.321826\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.041908\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.208258\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.203409\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.135733\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.137442\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.148948\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.094926\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.248714\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.257484\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.114915\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.033494\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.312480\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.162341\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.211810\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.112995\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.232989\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.204318\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.182996\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.123061\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.279543\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.074004\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.123294\n",
      "\n",
      "Test set: Average loss: 0.0785, Accuracy: 9766/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.108125\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.259920\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.152708\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.261378\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.344165\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.184750\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.105615\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.118161\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.216003\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.142773\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.107229\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.128384\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.104206\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.057233\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.106044\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.282965\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.054871\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.089200\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.055828\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.080539\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.166300\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.092940\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.322685\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.045635\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.083720\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.274632\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.119661\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.128541\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.146128\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.247438\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.053463\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.067552\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.101163\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.186109\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.037888\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.084264\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.145882\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.099062\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.088006\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.209647\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.060588\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.122083\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.070682\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.093551\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.036260\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.144589\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.172233\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.031278\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.117385\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.104486\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.037208\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.179987\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.064133\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.240820\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.078185\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.148430\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.063479\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.198893\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.113113\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.065596\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.127707\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.104164\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.155695\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.117826\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.161900\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.093261\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.101396\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.176261\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.043122\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.083462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.081467\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.026983\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.029528\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.174082\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.122709\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.070154\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.083151\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.044301\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.055816\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.208419\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.032888\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.179407\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.199686\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.023887\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.037393\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.094247\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.030548\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.035678\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.133128\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.035359\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.117677\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.048272\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.173686\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.038031\n",
      "\n",
      "Test set: Average loss: 0.0564, Accuracy: 9833/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.135554\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.038987\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.140593\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.020462\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.093107\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.051028\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.130622\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.121756\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.019152\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.022712\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.086554\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.028211\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.195363\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.042770\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.141296\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.029310\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.013092\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.040119\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.100142\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.076827\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.056513\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.043352\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.038254\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.129651\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.135625\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.038627\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.054018\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.074535\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.028033\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.021415\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.128712\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.084766\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.069137\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.126863\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.049951\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.113845\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.054697\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.112034\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.134118\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.032074\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.064175\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.101782\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.076060\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.027071\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.032945\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.100075\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.049765\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.167514\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.030714\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.086938\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.102115\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.169120\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.097329\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.028372\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.085530\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.076591\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.060540\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.009729\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.169289\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.033247\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.016858\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.035180\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.078619\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.036353\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.053714\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.075420\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.014699\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.053982\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.133931\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.160666\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.057547\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.089268\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.011176\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.046969\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.232834\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.015958\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.092926\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.011661\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.061765\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.126502\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.023638\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.068050\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.146953\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.022365\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.058980\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.158163\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.041880\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.013712\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.086623\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.112131\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.014801\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.010471\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.161468\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.118827\n",
      "\n",
      "Test set: Average loss: 0.0462, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.014964\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.029173\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.135825\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.098839\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.059377\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.049377\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.045035\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.400208\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.034155\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.053190\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.041405\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.023032\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.090572\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.011462\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.052264\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.013625\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.123334\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.029607\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.084014\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.036133\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.082034\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.080424\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.044509\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.031669\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.018585\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.247489\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.077960\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.058928\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.113468\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.079992\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.086186\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.026751\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.048479\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.079539\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.026016\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.029555\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.075100\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.090882\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.030093\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.088281\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.084548\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.124441\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.028871\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.139128\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.021145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.146458\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.085150\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.012985\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.057992\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.013348\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.072572\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.053648\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.111272\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.045711\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.056876\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.030068\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.020170\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.075423\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.030893\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.090687\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.050275\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.052832\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.047415\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.121579\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.081532\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.089932\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.044069\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.078359\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.114281\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.150910\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.050616\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.064176\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.083884\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.019219\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.171038\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.036153\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.059224\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.082881\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.019253\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.009168\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.048739\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.036557\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.031297\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.198384\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.148342\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.066864\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.022230\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.103651\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.054371\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.035802\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.048820\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.037806\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.031063\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.063452\n",
      "\n",
      "Test set: Average loss: 0.0415, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.031797\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.029070\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.032623\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.078560\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.051398\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.026460\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.031800\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.261747\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.104266\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.172227\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.048445\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.041884\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.006290\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.030473\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.017585\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.045417\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.103269\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.056535\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.151622\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.230584\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.029000\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.044957\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.120634\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.076219\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.008170\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.073233\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.042274\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.033734\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.060687\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.019206\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.044946\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.080803\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.062442\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.032980\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.038856\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.010415\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.086019\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.133466\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.079475\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.079986\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.136888\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.007266\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.046529\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.081582\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.052199\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.011854\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.019852\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.035403\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.012425\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.138332\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.054767\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.047265\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.008975\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.019616\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.254221\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.166684\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.012018\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.021150\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.030307\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.029735\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.141321\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.006834\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.009739\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.194619\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.024367\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.014375\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.035267\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.054810\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.050817\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.116356\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.034233\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.022784\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.044513\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.018018\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.020052\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.034476\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.109597\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.016076\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.023497\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.110583\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.086618\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.070146\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.129264\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.063889\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.077004\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.054547\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.077140\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.085738\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.020058\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.027893\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.018554\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.019385\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.075834\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.068588\n",
      "\n",
      "Test set: Average loss: 0.0406, Accuracy: 9868/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.014274\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.011565\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.107976\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.098498\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.094872\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.116621\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.040152\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.041068\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.004412\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.120298\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.035074\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.051232\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.065991\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.120918\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.121741\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.060810\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.013936\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.043099\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.013569\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.056388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.126920\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.018149\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.043758\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.094003\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.026484\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.036120\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.149191\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.047744\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.035456\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.013141\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.041890\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.017299\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.058239\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.041384\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.020726\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.080272\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.017536\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.021299\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.084909\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.012700\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.185301\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.055405\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.081782\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.086258\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.014461\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.046816\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.057552\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.064717\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.022478\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.009416\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.061876\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.054380\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.170368\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.019942\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.183967\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.086877\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.135393\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.035565\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.053558\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.136114\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.152052\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.108716\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.119729\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.006442\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.114851\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.018896\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.027204\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.204957\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.008348\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.038779\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.170254\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.095425\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.066918\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.029665\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.079293\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.033819\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.024922\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.045184\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.035749\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.103393\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.061831\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.145659\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.196177\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.019704\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.024017\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.096563\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.092888\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.021853\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.026980\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.064850\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.086947\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.095106\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.063050\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.047155\n",
      "\n",
      "Test set: Average loss: 0.0392, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.050063\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.060291\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.069559\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.039188\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.079567\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.011904\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.078249\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.086608\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.046947\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.036978\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.121381\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.038730\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.006109\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.027995\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.022077\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.029247\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.032985\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.054446\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.095537\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.032165\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.073002\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.046496\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.022919\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.040508\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.043575\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.012662\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.019160\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.064108\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.100605\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.068446\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.032209\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.063056\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.061977\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.095458\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.013028\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.032248\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.049232\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.027677\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.004241\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.147107\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.146079\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.032615\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.070487\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.012719\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.161619\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.030870\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.023659\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.060095\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.096678\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.063432\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.015145\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.091294\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.092537\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.044101\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.042862\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.165433\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.111376\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.037752\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.109147\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.068881\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.052015\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.038702\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.013449\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.012543\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.023586\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.099305\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.115666\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.003193\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.079705\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.027301\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.086308\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.050662\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.018988\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.009140\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.018388\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.107104\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.079466\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.023552\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.025319\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.010153\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.177590\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.164735\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.021607\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.056604\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.007807\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.175628\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.043905\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.142707\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.037525\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.070973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.057735\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.116418\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.040386\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.140920\n",
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.012101\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.035058\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.029777\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.020061\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.124362\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.021006\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.014084\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.021637\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.086772\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.174961\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.215024\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.019618\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.104898\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.036012\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.011140\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.028724\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.016422\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.029346\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.009462\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.090787\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.044620\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.012687\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.032172\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.035452\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.097234\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.084064\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.010747\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.128811\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.091605\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.008224\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.210801\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.058386\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.011748\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.023720\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.020001\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.022304\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.038535\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.129923\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.103420\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.083077\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.084949\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.145532\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.006923\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.110508\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.015111\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.061338\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.084543\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.023388\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.014184\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.063442\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.062641\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.060154\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.150610\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.034999\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.076255\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.091179\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.153534\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.103126\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.145553\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.066353\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.028232\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.051539\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.090719\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.030559\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.043050\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.080863\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.009546\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.125104\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.115934\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.094435\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.006139\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.114900\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.049083\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.051121\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.120914\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.038252\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.081711\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.140792\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.013303\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.085119\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.031909\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.079585\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.042680\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.133650\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.039566\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.172533\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.054870\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.038551\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.063554\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.073152\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.093478\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.026816\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.031211\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.032160\n",
      "\n",
      "Test set: Average loss: 0.0385, Accuracy: 9871/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.043199\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.031608\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.070086\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.021566\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.018604\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.005674\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.010420\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.048211\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.231798\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.038684\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.028412\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.014926\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.063827\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.046754\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.094906\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.075714\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.032005\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.058047\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.112655\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.026818\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.032549\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.180705\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.096915\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.034140\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.039676\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.271018\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.032268\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.115942\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.051910\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.109814\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.128855\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.033970\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.049914\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.048976\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.043889\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.156670\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.006590\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.161296\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.026664\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.057504\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.014845\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.031437\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.034746\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.168616\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.024340\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.089969\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.138990\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.070057\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.013934\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.041226\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.142413\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.023296\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.069102\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.090951\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.041695\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.132639\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.090798\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.098910\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.021126\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.017977\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.040805\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.100961\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.048882\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.125745\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.002946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.063448\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.010434\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.008941\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.204202\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.066305\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.016946\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.073747\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.015461\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.088175\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.004959\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.050445\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.044972\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.031738\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.157733\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.018779\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.026275\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.005043\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.071828\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.060817\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.066188\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.020354\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.071540\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.026585\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.057867\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.023847\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.186322\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.017757\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.073938\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.013959\n",
      "\n",
      "Test set: Average loss: 0.0376, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.028079\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.056839\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.126329\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.018966\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.160041\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.014476\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.090883\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.046794\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.011203\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.026422\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.083421\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.022276\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.058870\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.070131\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.031830\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.175458\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.024814\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.007356\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.052466\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.066387\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.021266\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.084238\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.016723\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.172433\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.022994\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.009613\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.042508\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.028295\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.012347\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.070493\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.026502\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.023952\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.109685\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.024387\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.209346\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.020113\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.013415\n",
      "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.022329\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.019007\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.054760\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.010968\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.034005\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.171677\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.015403\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.020659\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.037955\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.004814\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.124419\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.098879\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.014026\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.133608\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.011704\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.011196\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.119809\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.062607\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.177290\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.121294\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.024814\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.090065\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.059087\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.009689\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.053465\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.145403\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.056335\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.057595\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.058513\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.084494\n",
      "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.053810\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.008160\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.031384\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.024809\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.140143\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.073447\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.009761\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.042508\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.008827\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.175124\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.016551\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.046726\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.057812\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.125939\n",
      "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.022041\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.096303\n",
      "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.015754\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.025928\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.018834\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.008863\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.084875\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.049873\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.129143\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.022511\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.150421\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.047603\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.050225\n",
      "\n",
      "Test set: Average loss: 0.0377, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.106521\n",
      "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.007803\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.137414\n",
      "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.036431\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.088830\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.059330\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.093720\n",
      "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.087591\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.028565\n",
      "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.025003\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.090328\n",
      "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.010133\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.068117\n",
      "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.053219\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.265234\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.032842\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.067252\n",
      "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.300565\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.056600\n",
      "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.089601\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.048256\n",
      "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.048506\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.043298\n",
      "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.133030\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.071309\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.005965\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.029998\n",
      "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.117033\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.133991\n",
      "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.109808\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.032434\n",
      "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.027284\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.186223\n",
      "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.022513\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.042694\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.041107\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.063562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.027014\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.118115\n",
      "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.141170\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.029257\n",
      "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.023919\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.267834\n",
      "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.007144\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.130762\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.076435\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.017946\n",
      "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.039395\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.018130\n",
      "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.095822\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.072353\n",
      "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.019555\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.087774\n",
      "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.035154\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.026557\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.060714\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.004798\n",
      "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.032798\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.021882\n",
      "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.007368\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.042800\n",
      "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.003574\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.069113\n",
      "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.197000\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.032555\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.111779\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.046943\n",
      "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.070388\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.151900\n",
      "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.028472\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.057173\n",
      "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.032502\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.033785\n",
      "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.087979\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.190295\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.036538\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.036110\n",
      "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.193674\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.096404\n",
      "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.092463\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.080841\n",
      "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.013602\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.024335\n",
      "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.015496\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.027345\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.034964\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.066888\n",
      "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.069332\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.144087\n",
      "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.082041\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.013297\n",
      "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.043905\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.035015\n",
      "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.055337\n",
      "\n",
      "Test set: Average loss: 0.0371, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.226585\n",
      "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.040320\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.039074\n",
      "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.019867\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.011537\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.033217\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.047618\n",
      "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.022658\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.142917\n",
      "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.004851\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.168017\n",
      "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.033062\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.046175\n",
      "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.021290\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.079910\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.034463\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.007313\n",
      "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.032652\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.081688\n",
      "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.036097\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.005252\n",
      "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.067961\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.216479\n",
      "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.058665\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.007059\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.054991\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.012116\n",
      "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.071871\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.020356\n",
      "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.084389\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.074322\n",
      "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.037276\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.060987\n",
      "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.007467\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.194561\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.029082\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.055019\n",
      "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.097077\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.056523\n",
      "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.136688\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.046788\n",
      "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.014669\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.048421\n",
      "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.055277\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.026679\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.063245\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.021385\n",
      "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.142781\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.028963\n",
      "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.057594\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.167940\n",
      "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.014729\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.012957\n",
      "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.121740\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.016798\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.063611\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.193969\n",
      "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.062403\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.101006\n",
      "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.047372\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.024950\n",
      "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.021766\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.009045\n",
      "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.133245\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.149293\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.004427\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.098947\n",
      "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.083618\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.009904\n",
      "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.019746\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.039098\n",
      "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.053067\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.048666\n",
      "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.029875\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.028318\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.034719\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.143906\n",
      "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.021956\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.007225\n",
      "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.071669\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.054611\n",
      "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.032285\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.022314\n",
      "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.053283\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.122992\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.039623\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.099828\n",
      "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.039997\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.024577\n",
      "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.207705\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.016251\n",
      "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.064409\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.056826\n",
      "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.058770\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.054502\n",
      "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.120992\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.032194\n",
      "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.028965\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.020586\n",
      "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.015219\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.064448\n",
      "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.010348\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.058292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.017623\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.067351\n",
      "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.031262\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.016828\n",
      "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.107384\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.073274\n",
      "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.072028\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.017689\n",
      "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.049223\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.060404\n",
      "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.025877\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.007500\n",
      "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.053719\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.014229\n",
      "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.075385\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.071272\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.078588\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.057084\n",
      "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.167235\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.118101\n",
      "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.031456\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.027713\n",
      "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.053318\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.048094\n",
      "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.029454\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.016330\n",
      "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.050061\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.039885\n",
      "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.028615\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.006584\n",
      "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.008558\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.176052\n",
      "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.151441\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.019247\n",
      "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.091561\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.010341\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.005653\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.012206\n",
      "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.181835\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.020035\n",
      "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.019561\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.017259\n",
      "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.131030\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.099843\n",
      "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.058751\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.116190\n",
      "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.052439\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.052589\n",
      "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.181420\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.043290\n",
      "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.040820\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.053536\n",
      "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.096902\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.056322\n",
      "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.005886\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.070839\n",
      "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.035465\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.026437\n",
      "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.026750\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.043099\n",
      "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.119302\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.082622\n",
      "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.041977\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.070521\n",
      "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.100975\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.015643\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.032689\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.250724\n",
      "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.025406\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.018649\n",
      "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.073851\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.134066\n",
      "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.042989\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.006921\n",
      "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.085160\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.070808\n",
      "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.085310\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.069398\n",
      "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.108903\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.016522\n",
      "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.054469\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.040873\n",
      "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.053678\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.169535\n",
      "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.013769\n",
      "\n",
      "Test set: Average loss: 0.0371, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.073378\n",
      "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.067857\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.052136\n",
      "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.043148\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.037554\n",
      "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.065336\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.046297\n",
      "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.039851\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.079315\n",
      "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.017636\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.224749\n",
      "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.052902\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.009735\n",
      "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.187123\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.037530\n",
      "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.096452\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.009238\n",
      "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.039717\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.007408\n",
      "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.068120\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.052408\n",
      "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.082532\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.041176\n",
      "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.095158\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.008693\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.007824\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.014394\n",
      "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.029459\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.035366\n",
      "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.113912\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.011532\n",
      "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.043883\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.045670\n",
      "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.049982\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.025226\n",
      "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.027459\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.048032\n",
      "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.092088\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.149850\n",
      "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.012022\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.042273\n",
      "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.105088\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.013932\n",
      "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.093740\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.081130\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.040359\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.010087\n",
      "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.033379\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.057244\n",
      "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.018153\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.051687\n",
      "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.057471\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.112531\n",
      "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.008270\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.024157\n",
      "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.012102\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.055455\n",
      "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.033622\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.041811\n",
      "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.169519\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.063482\n",
      "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.018794\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.279283\n",
      "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.008471\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.011913\n",
      "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.068193\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.211064\n",
      "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.033171\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.015043\n",
      "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.106590\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.048251\n",
      "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.017372\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.028424\n",
      "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.105489\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.012304\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.058544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.023392\n",
      "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.066030\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.046026\n",
      "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.031265\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.066087\n",
      "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.041565\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.059493\n",
      "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.044823\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.084210\n",
      "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.076470\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.056437\n",
      "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.131999\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.013175\n",
      "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.211623\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.034819\n",
      "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.178766\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.008415\n",
      "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.022785\n",
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.044062\n",
      "Train Epoch: 15 [640/60000 (1%)]\tLoss: 0.090683\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.034395\n",
      "Train Epoch: 15 [1920/60000 (3%)]\tLoss: 0.021938\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.035371\n",
      "Train Epoch: 15 [3200/60000 (5%)]\tLoss: 0.088577\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.083847\n",
      "Train Epoch: 15 [4480/60000 (7%)]\tLoss: 0.039022\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.093311\n",
      "Train Epoch: 15 [5760/60000 (10%)]\tLoss: 0.024607\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.124437\n",
      "Train Epoch: 15 [7040/60000 (12%)]\tLoss: 0.026283\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.029980\n",
      "Train Epoch: 15 [8320/60000 (14%)]\tLoss: 0.095652\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.038149\n",
      "Train Epoch: 15 [9600/60000 (16%)]\tLoss: 0.064905\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.019923\n",
      "Train Epoch: 15 [10880/60000 (18%)]\tLoss: 0.009844\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.045303\n",
      "Train Epoch: 15 [12160/60000 (20%)]\tLoss: 0.152810\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.057683\n",
      "Train Epoch: 15 [13440/60000 (22%)]\tLoss: 0.036444\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.059708\n",
      "Train Epoch: 15 [14720/60000 (25%)]\tLoss: 0.130491\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.018616\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.028246\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.069016\n",
      "Train Epoch: 15 [17280/60000 (29%)]\tLoss: 0.115915\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.164782\n",
      "Train Epoch: 15 [18560/60000 (31%)]\tLoss: 0.139998\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.026977\n",
      "Train Epoch: 15 [19840/60000 (33%)]\tLoss: 0.062177\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.069526\n",
      "Train Epoch: 15 [21120/60000 (35%)]\tLoss: 0.139052\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.015323\n",
      "Train Epoch: 15 [22400/60000 (37%)]\tLoss: 0.081717\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.020906\n",
      "Train Epoch: 15 [23680/60000 (39%)]\tLoss: 0.025612\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.026137\n",
      "Train Epoch: 15 [24960/60000 (42%)]\tLoss: 0.244057\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.029097\n",
      "Train Epoch: 15 [26240/60000 (44%)]\tLoss: 0.023651\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.015810\n",
      "Train Epoch: 15 [27520/60000 (46%)]\tLoss: 0.111796\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.130415\n",
      "Train Epoch: 15 [28800/60000 (48%)]\tLoss: 0.074725\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.112780\n",
      "Train Epoch: 15 [30080/60000 (50%)]\tLoss: 0.073220\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.014936\n",
      "Train Epoch: 15 [31360/60000 (52%)]\tLoss: 0.089112\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.115587\n",
      "Train Epoch: 15 [32640/60000 (54%)]\tLoss: 0.016605\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.082868\n",
      "Train Epoch: 15 [33920/60000 (57%)]\tLoss: 0.008810\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.069804\n",
      "Train Epoch: 15 [35200/60000 (59%)]\tLoss: 0.036520\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.036039\n",
      "Train Epoch: 15 [36480/60000 (61%)]\tLoss: 0.019090\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.060788\n",
      "Train Epoch: 15 [37760/60000 (63%)]\tLoss: 0.024759\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.009989\n",
      "Train Epoch: 15 [39040/60000 (65%)]\tLoss: 0.044454\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.051774\n",
      "Train Epoch: 15 [40320/60000 (67%)]\tLoss: 0.027186\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.027624\n",
      "Train Epoch: 15 [41600/60000 (69%)]\tLoss: 0.046456\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.155792\n",
      "Train Epoch: 15 [42880/60000 (71%)]\tLoss: 0.023869\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.015960\n",
      "Train Epoch: 15 [44160/60000 (74%)]\tLoss: 0.142186\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.140934\n",
      "Train Epoch: 15 [45440/60000 (76%)]\tLoss: 0.013627\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.023981\n",
      "Train Epoch: 15 [46720/60000 (78%)]\tLoss: 0.025002\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.052094\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.101036\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.015331\n",
      "Train Epoch: 15 [49280/60000 (82%)]\tLoss: 0.020625\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.055373\n",
      "Train Epoch: 15 [50560/60000 (84%)]\tLoss: 0.012383\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.026064\n",
      "Train Epoch: 15 [51840/60000 (86%)]\tLoss: 0.164119\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.043710\n",
      "Train Epoch: 15 [53120/60000 (88%)]\tLoss: 0.076859\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.005826\n",
      "Train Epoch: 15 [54400/60000 (91%)]\tLoss: 0.023793\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.012673\n",
      "Train Epoch: 15 [55680/60000 (93%)]\tLoss: 0.165706\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.023984\n",
      "Train Epoch: 15 [56960/60000 (95%)]\tLoss: 0.004970\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.031127\n",
      "Train Epoch: 15 [58240/60000 (97%)]\tLoss: 0.026009\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.072730\n",
      "Train Epoch: 15 [59520/60000 (99%)]\tLoss: 0.115968\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 9874/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.015849\n",
      "Train Epoch: 16 [640/60000 (1%)]\tLoss: 0.021255\n",
      "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.091969\n",
      "Train Epoch: 16 [1920/60000 (3%)]\tLoss: 0.015307\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.005147\n",
      "Train Epoch: 16 [3200/60000 (5%)]\tLoss: 0.058102\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.115723\n",
      "Train Epoch: 16 [4480/60000 (7%)]\tLoss: 0.019887\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.246970\n",
      "Train Epoch: 16 [5760/60000 (10%)]\tLoss: 0.035481\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.027428\n",
      "Train Epoch: 16 [7040/60000 (12%)]\tLoss: 0.048335\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.013513\n",
      "Train Epoch: 16 [8320/60000 (14%)]\tLoss: 0.103036\n",
      "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.135404\n",
      "Train Epoch: 16 [9600/60000 (16%)]\tLoss: 0.057335\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.063612\n",
      "Train Epoch: 16 [10880/60000 (18%)]\tLoss: 0.187011\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.065619\n",
      "Train Epoch: 16 [12160/60000 (20%)]\tLoss: 0.016017\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.133489\n",
      "Train Epoch: 16 [13440/60000 (22%)]\tLoss: 0.012635\n",
      "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.002436\n",
      "Train Epoch: 16 [14720/60000 (25%)]\tLoss: 0.010055\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.040639\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.005841\n",
      "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.191452\n",
      "Train Epoch: 16 [17280/60000 (29%)]\tLoss: 0.020897\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.021772\n",
      "Train Epoch: 16 [18560/60000 (31%)]\tLoss: 0.008731\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.069611\n",
      "Train Epoch: 16 [19840/60000 (33%)]\tLoss: 0.230142\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.022325\n",
      "Train Epoch: 16 [21120/60000 (35%)]\tLoss: 0.184929\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.024187\n",
      "Train Epoch: 16 [22400/60000 (37%)]\tLoss: 0.029886\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.065457\n",
      "Train Epoch: 16 [23680/60000 (39%)]\tLoss: 0.051209\n",
      "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.047144\n",
      "Train Epoch: 16 [24960/60000 (42%)]\tLoss: 0.018678\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.033952\n",
      "Train Epoch: 16 [26240/60000 (44%)]\tLoss: 0.036836\n",
      "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.019638\n",
      "Train Epoch: 16 [27520/60000 (46%)]\tLoss: 0.014558\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.070564\n",
      "Train Epoch: 16 [28800/60000 (48%)]\tLoss: 0.018746\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.055242\n",
      "Train Epoch: 16 [30080/60000 (50%)]\tLoss: 0.008566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.042133\n",
      "Train Epoch: 16 [31360/60000 (52%)]\tLoss: 0.045969\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.154172\n",
      "Train Epoch: 16 [32640/60000 (54%)]\tLoss: 0.221706\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.163963\n",
      "Train Epoch: 16 [33920/60000 (57%)]\tLoss: 0.044652\n",
      "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.035362\n",
      "Train Epoch: 16 [35200/60000 (59%)]\tLoss: 0.011358\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.085615\n",
      "Train Epoch: 16 [36480/60000 (61%)]\tLoss: 0.105816\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.074874\n",
      "Train Epoch: 16 [37760/60000 (63%)]\tLoss: 0.050208\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.088319\n",
      "Train Epoch: 16 [39040/60000 (65%)]\tLoss: 0.011977\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.219594\n",
      "Train Epoch: 16 [40320/60000 (67%)]\tLoss: 0.050883\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.093366\n",
      "Train Epoch: 16 [41600/60000 (69%)]\tLoss: 0.041924\n",
      "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.104504\n",
      "Train Epoch: 16 [42880/60000 (71%)]\tLoss: 0.111421\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.105675\n",
      "Train Epoch: 16 [44160/60000 (74%)]\tLoss: 0.018694\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.104478\n",
      "Train Epoch: 16 [45440/60000 (76%)]\tLoss: 0.019589\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.096344\n",
      "Train Epoch: 16 [46720/60000 (78%)]\tLoss: 0.020877\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.029846\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.039395\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.112316\n",
      "Train Epoch: 16 [49280/60000 (82%)]\tLoss: 0.109722\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.052996\n",
      "Train Epoch: 16 [50560/60000 (84%)]\tLoss: 0.061010\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.063795\n",
      "Train Epoch: 16 [51840/60000 (86%)]\tLoss: 0.024452\n",
      "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.008287\n",
      "Train Epoch: 16 [53120/60000 (88%)]\tLoss: 0.192088\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.050479\n",
      "Train Epoch: 16 [54400/60000 (91%)]\tLoss: 0.007335\n",
      "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.022397\n",
      "Train Epoch: 16 [55680/60000 (93%)]\tLoss: 0.037504\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.028746\n",
      "Train Epoch: 16 [56960/60000 (95%)]\tLoss: 0.079315\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.051210\n",
      "Train Epoch: 16 [58240/60000 (97%)]\tLoss: 0.151918\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.020878\n",
      "Train Epoch: 16 [59520/60000 (99%)]\tLoss: 0.011873\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 9873/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(2022)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': 2 * 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.MNIST(path / 'mnist', train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = datasets.MNIST(path / 'mnist', train=False,\n",
    "                   transform=transform)\n",
    "train_loader = DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), path / 'mnist' / 'mnist_cnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train letters classificartion with convolutional neural networkm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = path / 'geomnist_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoletters = path / 'geoletters'\n",
    "geoletters.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cp /content/drive/My\\ Drive/datasets/letters/trained_data/geomnist_dataset.zip {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://github.com/MaxinAI/school-of-ai/raw/master/data/geoletters/geomnist_dataset.zip {geoletters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile(path / 'geoletters' / 'geomnist_dataset.zip' , 'r') as zip_ref:\n",
    "#     zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_loader(img_path:Path):\n",
    "    with open(img_path, mode='rb') as fl:\n",
    "        with PIL.Image.open(fl) as img:\n",
    "            return img.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(image_path / 'train_geo', loader=img_loader, transform=tfms)\n",
    "valid_dataset = datasets.ImageFolder(image_path / 'val_geo', loader=img_loader, transform=tfms)\n",
    "test_dataset = datasets.ImageFolder(image_path / 'test_geo', loader=img_loader, transform=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, \n",
    "                          num_workers=workers, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, \n",
    "                          num_workers=workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,\n",
    "                        num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.1307])\n",
    "    std = np.array([0.3081])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(64, 64))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[classes[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?? nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_body = nn.Sequential(OrderedDict([('conv1', nn.Conv2d(input_channels, 32, 3)),\n",
    "                                        ('bn1', nn.BatchNorm2d(32)),\n",
    "                                        ('relu1', nn.ReLU(inplace=True)),\n",
    "                                        ('mxpl1', nn.MaxPool2d(2, 2)),\n",
    "                                        ('conv2', nn.Conv2d(32, 64, kernel_size=3)),\n",
    "                                        ('bn2', nn.BatchNorm2d(64)),\n",
    "                                        ('relu2', nn.ReLU(inplace=True)),\n",
    "                                        ('mxpl2', nn.MaxPool2d(2, 2)),\n",
    "                                        ('drop1', nn.Dropout2d(p=0.25))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_body = nn.Sequential(OrderedDict([('conv3', nn.Conv2d(64, 128, kernel_size=3)),\n",
    "                                       ('bn3', nn.BatchNorm2d(128)),\n",
    "                                       ('relu3', nn.ReLU(inplace=True)),\n",
    "                                       ('mxpl3', nn.MaxPool2d(2, 2)),\n",
    "                                       ('drop2', nn.Dropout2d(p=0.25))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_body = nn.Sequential(OrderedDict([('flatten', nn.Flatten()),\n",
    "                                         ('ln1', nn.Linear(2 * 2 * 128, 1024, bias=True)),\n",
    "                                         ('bn2', nn.BatchNorm1d(1024)),\n",
    "                                         ('relu3', nn.ReLU(inplace=True)),\n",
    "                                         ('drop2', nn.Dropout(p=0.25))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterNet(nn.Module):\n",
    "    \"\"\"Full double letters network implementation\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels=1, num_classes=33):\n",
    "        super(LetterNet, self).__init__()\n",
    "        self.conv_part = lower_body\n",
    "        self.dub_part = conv_body\n",
    "        self.fc_part = linear_body\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_part(x)\n",
    "        x = self.dub_part(x)\n",
    "        x = self.fc_part(x)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_out(w:int, k: int, p: int, s: int):\n",
    "    return int(((w - k + 2*p)/s)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out(32, 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_out(conv_out(conv_out(conv_out(32, 3, 0, 1), 2, 0, 1), 3, 0, 1), 2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterNet2(nn.Module):\n",
    "    \"\"\"Full double letters network implementation\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels=1, num_classes=33):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(6 * 6 * 64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "#         logits = self.pool2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 32 # 34\n",
    "x_test = torch.randn(4 , 1, sz, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LetterNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_test = model(x_test)\n",
    "o_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LetterNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNetLt(LightningModule):\n",
    "    def __init__(\n",
    "        self, model: nn.Module, loss_fn=loss_func, metrics=Accuracy()):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.accuracy = metrics\n",
    "        self.lr=0.01\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        loss = self.loss_fn(z, y)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "        loss = self.loss_fn(z, y)\n",
    "        preds = torch.argmax(z, dim=1)\n",
    "        self.accuracy(preds, y)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.accuracy, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        lr_scheduler_cos = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, \n",
    "            T_0=10, T_mult=2, \n",
    "            eta_min=0.0001, \n",
    "            last_epoch=-1,\n",
    "            verbose=True)\n",
    "        \n",
    "        return [optimizer], [lr_scheduler_cos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "AVAIL_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lt = ClassifierNetLt(model)\n",
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=8,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    auto_lr_find=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {geoletters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_date = datetime.now().strftime('%d_%m_%Y').lower()\n",
    "curr_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geletters_ckpts = geoletters / f'geoletters_{curr_date}'\n",
    "geletters_ckpts.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model_lt, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lt_lr = ClassifierNetLt(LetterNet())\n",
    "trainer_lr = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    max_epochs=3,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    auto_lr_find=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = trainer_lr.tuner.lr_find(\n",
    "    model_lt_lr, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results can be found in\n",
    "lr_finder.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick point based on plot, or get suggestion\n",
    "new_lr = lr_finder.suggestion()\n",
    "\n",
    "# update hparams of the model\n",
    "model_lt_lr.lr = new_lr\n",
    "new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_lr.tune(\n",
    "    model_lt_lr, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 32 # 34\n",
    "x_test = torch.randn(4 , 1, sz, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_lt.freeze()\n",
    "model_lt(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Bigger Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=False, progress=True)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-initialize data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2 * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, \n",
    "                          num_workers=workers, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, \n",
    "                          num_workers=workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False,\n",
    "                        num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_lt = ClassifierNetLt(resnet)\n",
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    benchmark=True,\n",
    "    max_epochs=16,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    auto_lr_find=True,\n",
    "    stochastic_weight_avg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    resnet_lt, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet_lt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_lt.model.state_dict(), str(geletters_ckpts / 'resnet_18_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_ld = models.resnet18(pretrained=False, progress=False)\n",
    "resnet_ld.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(str(geletters_ckpts / 'resnet_18_state_dict.pth'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_ld.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geletters_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls {geletters_ckpts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_lt.model, geletters_ckpts / 'resnet_18_entire.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_ld = torch.load(geletters_ckpts / 'resnet_18_entire.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_ld.state_dict(), resnet_lt.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference service in different session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install -U flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geletters_ckpts / 'resnet_18_entire.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data/geoletters/geoletters_labels.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geletters_ckpts.absolute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad\n",
    "from torch.jit import ScriptModule\n",
    "from torchvision.models import (resnet34, resnet50, wide_resnet50_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "imsz = 224\n",
    "IMG_SUFF = {'.jpg', '.jpeg', '.png'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToPILImage(object):\n",
    "    \"\"\"Convert inout image to PIL image\"\"\"\n",
    "\n",
    "    def __init__(self, mode=None):\n",
    "        super().__init__()\n",
    "        self.to_pil = transforms.ToPILImage(mode=mode)\n",
    "\n",
    "    def convert(self, img: Union[np.ndarray, PIL.Image.Image]):\n",
    "        \"\"\"\n",
    "        Converts image to the PIL format\n",
    "        Args:\n",
    "            img: inout image\n",
    "\n",
    "        Returns:\n",
    "            converted image\n",
    "        \"\"\"\n",
    "        return img if isinstance(img, PIL.Image.Image) else self.to_pil(img)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.convert(*args, **kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        if self.to_pil.mode is not None:\n",
    "            format_string += f'mode={self.to_pil.mode}'\n",
    "        format_string += ')'\n",
    "        return format_string\n",
    "\n",
    "\n",
    "class Img2Vec(object):\n",
    "    \"\"\"Model wrapper for image embedding\"\"\"\n",
    "\n",
    "    def __init__(self, backbone: Union[nn.Module, ScriptModule], trfm: transforms, device: str = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(device)\n",
    "        self.backbone = (backbone.eval() if hasattr(backbone, 'eval') else backbone).to(device)\n",
    "        self.trfm = trfm\n",
    "\n",
    "    def preprocess(self, *xs: Union[np.ndarray, PIL.Image.Image]) -> Tensor:\n",
    "        \"\"\"\n",
    "        Transform data before model\n",
    "        Args:\n",
    "            *xs: input data\n",
    "\n",
    "        Returns:\n",
    "            processed data for model\n",
    "        \"\"\"\n",
    "        return torch.stack([self.trfm(x) for x in xs]).to(self.device)\n",
    "\n",
    "    @no_grad()\n",
    "    def forward(self, *xs: np.ndarray) -> np.ndarray:\n",
    "        tns = self.preprocess(*xs)\n",
    "        rts = self.backbone(tns)\n",
    "        y = rts.cpu().data.numpy()\n",
    "\n",
    "        return y\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_trsfm = transforms.Compose([ToPILImage(mode='RGB'),\n",
    "                                transforms.Resize(size),\n",
    "                                transforms.CenterCrop(imsz),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_path = path / 'search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_paths = [dp for dp in search_path.iterdir() if dp.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pts = [im_pt for dp in dir_paths for im_pt in dp.iterdir() if im_pt.suffix in IMG_SUFF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(im_pt):\n",
    "    img = cv2.imread(str(im_pt), cv2.IMREAD_ANYCOLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [read_img(ip) for ip in img_pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize features extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = wide_resnet50_2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = nn.Sequential(*list(body.children())[:-cut])\n",
    "net = nn.Sequential(backbone, nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec = Img2Vec(net, vec_trsfm, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(imgs, desc='Vectorizing images') as p_imgs:\n",
    "    vecs = [img_vec(im)[0] for im in p_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs[0].shape, len(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vecs = list(zip(imgs, vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_vecs(qi, vec_func=img_vec, db=img_vecs, top_k=5):\n",
    "    qv = vec_func(qi)[0]\n",
    "    resul_pts = [(cosine(qv, vc), pt) for pt, vc in db]\n",
    "    resul_pts = sorted(resul_pts, key=lambda x: x[0], reverse=False)\n",
    "    resul_pts = resul_pts[:top_k]\n",
    "    \n",
    "    return resul_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path = path / 'queries'\n",
    "query_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qim = read_img(query_path / 'ct_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = top_vecs(qim, vec_func=img_vec, db=img_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(qim)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dist, res_img in res:\n",
    "    plt.imshow(res_img)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image similarity with CLIP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec_clip = Img2Vec(model, preprocess, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vec_clip.backbone = img_vec_clip.backbone.encode_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(imgs, desc='Reading images') as p_paths:\n",
    "    pil_imgs = [Image.fromarray(im) for im in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??preprocess.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess(pil_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(pil_imgs, desc='Vectorizing images') as p_imgs:\n",
    "    clip_vecs = [img_vec_clip(im)[0] for im in p_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_img_vecs = list(zip(imgs, clip_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_vecs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path = path / 'queries'\n",
    "query_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qim = read_img(query_path / 'ct_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = top_vecs(Image.fromarray(qim), vec_func=img_vec_clip, db=clip_img_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(qim)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dist, res_img in res:\n",
    "    plt.imshow(res_img)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dlownload and store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hymenoptera = path / 'hymenoptera'\n",
    "hymenoptera.mkdir(exist_ok=True)\n",
    "hymenoptera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip -P {hymenoptera}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {hymenoptera}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(hymenoptera / 'hymenoptera_data.zip' , 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {path / 'hymenoptera_data'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "train_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "data_dir = path / 'hymenoptera_data'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir / 'train', train_transforms)\n",
    "val_dataset = datasets.ImageFolder(data_dir / 'val', val_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, \n",
    "                          num_workers=workers, drop_last=True)\n",
    "val_datloader = DataLoader(val_dataset, batch_size=64, shuffle=False, \n",
    "                          num_workers=workers)\n",
    "test_datloader = DataLoader(val_dataset, batch_size=4, shuffle=True, \n",
    "                          num_workers=workers)\n",
    "\n",
    "dataset_sizes = len(train_dataloader) + len(val_datloader)\n",
    "class_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(32, 32))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_dataloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    model.freeze()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(test_datloader):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]} ground true: {class_names[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(test_datloader):\n",
    "    print(i, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True, progress=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHymLt(ClassifierNetLt):\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_ft = optim.SGD(\n",
    "            self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "            optimizer_ft, step_size=7, gamma=0.1)\n",
    "        \n",
    "        return [optimizer_ft], [exp_lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft_lt = ClassifierHymLt(model_ft)\n",
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    benchmark=True,\n",
    "    max_epochs=32,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    auto_lr_find=True,\n",
    "#     stochastic_weight_avg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model_ft_lt, train_dataloader, val_datloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_model(model_ft_lt, num_images=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHymFtLt(ClassifierNetLt):\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_ft = optim.SGD(\n",
    "            self.model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "            optimizer_ft, step_size=7, gamma=0.1)\n",
    "        \n",
    "        return [optimizer_ft], [exp_lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft_lt = ClassifierHymFtLt(model_conv)\n",
    "trainer = Trainer(\n",
    "    gpus=AVAIL_GPUS,\n",
    "    benchmark=True,\n",
    "    max_epochs=32,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    auto_lr_find=True,\n",
    "#     stochastic_weight_avg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model_ft_lt, train_dataloader, val_datloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft_lt, num_images=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
